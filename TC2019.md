TC2018 Robot Setup
===
---
OS: Ubuntu 16.04  
Autoware: 1.9.0  
Robot: MAD mobile

# Menu

1. [Setup environment](#setup)
<!-- 1. <a href="setup">Setup environment</a> -->

1. [Set PC in the Robot](#set_pc)
<!-- 1. <a href="set pc">Set PC in the Robot</a> -->

1. <a href="power on">Power on the Robot</a>

1. <a href="manual">Manual control</a>

1. <a href="autonomous">Autonomous control</a>


<a id="setup"></a>
# Setup Environment
---
## install ROS

```bash
# ソフトウェアをaptでインストールできるように、インストール先のURLを追加
sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
# 鍵を設定
sudo apt-key adv --keyserver 'hkp://ha.pool.sks-keyservers.net:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654

sudo apt update
# インストール
sudo apt-get install ros-kinetic-ros-base
# rosdep初期化
sudo rosdep init
rosdep update
```

## install robot controller

### yp_spur_ros
```bash
mkdir -p ~/catkin_ws/src
cd ~/catkin_ws/src
catkin_init_workspace
git clone https://github.com/openspur/ypspur_ros.git
catkin_make -DCMAKE_BUILD_TYPE=Release
```
## install Autoware and other applications
```bash
sudo apt-get update

# install dependencies for autoware
sudo apt-get install -y python-catkin-pkg python-rosdep ros-$ROS_DISTRO-catkin gksu
sudo apt-get install -y python3-pip python3-colcon-common-extensions python3-setuptools python3-vcstool
pip3 install -U setuptools

# install
git clone https://github.com/TakedaLab/TC2018.git

# build autoware
cd ~/TC2019/autoware/ros
rosdep update
rosdep install -y --from-paths src --ignore-src --rosdistro kinetic
catkin_make -DCMAKE_BUILD_TYPE=Release

# build other packages
sudo apt install -y ros-kinetic-sound_play ros-kinetic-joy
cd ~/TC2019/catkin_ws/
catkin_make -DCMAKE_BUILD_TYPE=Release
```

## setup
1. setup velodyne
    1. install package
    ```bash
    sudo apt-get install ros-kinetic-velodyne
    ```
    1. setup ip address
    <image src="">
    1. check
    ```bash
    roslaunch velodyne_pointcloud 32e_points.launch
    rviz
    ```
1. get parameter file for MAD mobile and move it to ~/Params/ (default)

1. move sound file for joystick control

    ```bash
    sudo mv ~/TC2019/sound/*.wav /usr/share/sounds/robot_sounds
    ```


<a id="set_pc"></a>
# 2. Set PC in the Robot and Run
---

<a id="manual"></a>
# 4. Manual control
---
```bash
cd path/to/yp_kerberos
./mad_mobile.sh
```
### The way to control Robot

<image src="picture/joy.png" width=70%>

<a id="autonomous"></a>
# 5. Autonomous control
---
### Run Autoware
```bash
cd path/to/Autoware
./run
```

### Setup

<image src="picture/setup.png" width=50%>  

1. **Localizer**  
    Select localization sensor

2. **TF**  
    LiDAR position on the Robot

3. **Vehicle Model**  
    Default car model is set if you chose nothing.

### Map

<image src="picture/map.png" width=50%>  

1. **Point Cloud**  
    Path to point_cloud .pcd

2. **Vector Map**  
    If you use vector_map to set white line and traffic light on the map, input path to vector_map. If not, ignore this console.

3. **TF**  
    Path to tf file. (/path/to/autoware/ros/.config/tf/tf.launch)

### Sensing

<image src="picture/sensing.png" width=50%>  

1. **Velodyne VLP-16**  
    Input calibration setting file like   
    `/path/to/Autoware/ros/src/sensing/drivers/lidar/packages/velodyne/velodyne_pointcloud/params/VLP16db.yaml`

     <image src="picture/lidar_vlp16.png" width=50%>  


2. **voxel grid filter**  
    Creates a 3D voxel grid (think about a voxel grid as a set of tiny 3D boxes in space) over the input point cloud data. Then, in each voxel, all the points present will be approximated (i.e., downsampled) with their centroid.  

    <image src="picture/vox_grid_filter.png" width=50%>  

    + **leaf size [m]**  
        Voxel’s length of each side. The bigger this value is, the faster computer is. 0.2 is best value for outside. When you use inside, 0.1 is best.

    + **Measurement Range [m]**  
        Restrict the range of point cloud data. The smaller this value is, The faster computer is.
        Appropriate value is 50m

3. **ring_ground_filter**  
    Remove ground points not to be detected as objects. This filter is best choice compered to other filters. Out put data is broadcast to `/points_no_ground`.

    <image src="picture/ring_ground_filter.png" width=50%>  

### Computing

<image src="picture/computing.png" width=50%>  

1. **ndt_matching**

    <image src="picture/ndt.png" width=70%>  

    + **Error Thres**  

    + **Resolution**  
        It may good to have the same value with *leaf size*

    + **Step Size**  
        0.08 is the best value for this Robot’s speed!! This value is my secret spice to make ndt_maching stable ^o^.

    + **Transformation Epsilon**  

    + **Maximum iteration**  
        We need not tune this value. Iteration times is actually up to 12~20.

1. **lidar_euclidean_cluster_detect**  

    <image src="picture/lider_euclidean_cluster.png" width=50%>

    + **input_point_node**  
        If you use ground_filter, change input node from `/points_raw` to `/points_no_ground`

    + **keep_only_lanes_points**  
        Restrict detection range to alongside the road. This function reduce the nunber of detected obstacles and makes dp_planner work well.

    + **use_gpu**  
        *lidar_euclidean_cluster_detect* is heavy burden for computer. By distributing the calculation to GPU make computer work faster.

1. move robot to start point

1. run **way_planner**

    ```bash
    roslaunch way_planner way_planner.launch
    ```
    Select vector map.  
    If you use one which created in Hatem’s original map tool (which file extension is `.kml` ), check `KML` in **Map Source**.    
    If you use one which created in Autoware map tools, (which file extension is `.csv` ) ,check `Autoware` in **Map Source**.

1. set start point and goalpoint with Rviz (*initial pose*)

1. run **dp_planner**  

    ```bash
    roslaunch dp_planner dp_planner_outside2.launch
    ```

    + **Follow Distance [m]**  
    The distance to obstacles in front of the robot. The Robot follow obstacles keeping this distance.

    + **Avoiding Distance [m]**  
        If the distance to obstacles is this value, the robot will avoid the obstacles.

    + **Avoidance Limit [m]**  
        If the distance to obstacle is under this value, the robot will stop.

    + **Lateral Safety [m]**  
        Keep lateral distance from tf origin to obstacles.

        <image src="picture/lateral_safezone.png" width=50%>

    + **Longitudinal Safety [m]**  
        Keep longitudinal distance from tf origin to obstacles.

1. **pure_pursuit**

    <image src="picture/pure_pursuit.png" width=50%>

    + **Waypoint**  
        Run according to the speed described in the Waypoint.

    + **Dialog**  
        Run according to the speed set in the slider.

1. **twist_filter**

    <image src="picture/twist_filter.png" width=50%>

1. **vel_pose_connect**  

    <image src="picture/vel_pose_connect.png" width=50%>


## 7. Edit code for robot

1. **Run time manager**  
    Lower the minimum of the slider in *runtime_manager* (*dp_planner* [app])  to match the scale for the robot.  
    Change min and max value in
    `/path/to/Autoware/ros/src/util/packages/runtime_manager/scripts/computing.yaml`
    *ln 2480~*

2. **Obstacle Detection**  
    Change condition value in  
    `/path/to/Autoware/ros/src/computing/planning/motion/packages/dp_planner/nodes/RosHelpers.cpp` *ln 565~*

3. **Robot Motion**
    `/path/to/Autoware/ros/src/computing/planning/motion/packages/dp_planner/nodes/dp_planner_core.cpp`
