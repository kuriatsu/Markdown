TC2019 Robot Setup
===
---
OS: Ubuntu 16.04  
Autoware: 1.9.0  
Robot: MAD mobile

# Menu

1. [Setup environment](#setup)
<!-- 1. <a href="setup">Setup environment</a> -->

1. [Set PC in the Robot](#set_pc)
<!-- 1. <a href="set pc">Set PC in the Robot</a> -->

1. <a href="power on">Power on the Robot</a>

1. <a href="manual">Manual control</a>

1. <a href="autonomous">Autonomous control</a>


<a id="setup"></a>
# Setup Environment
---
## Install

### ROS
```bash
# ソフトウェアをaptでインストールできるように、インストール先のURLを追加
sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
# 鍵を設定
sudo apt-key adv --keyserver 'hkp://ha.pool.sks-keyservers.net:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654

sudo apt update
# インストール
sudo apt install ros-kinetic-ros-base
# rosdep初期化
sudo rosdep init
rosdep update
```
### Software (this repository)
```bash
git clone https://github.com/TakedaLab/TC2018.git ~/TC2019/
```

## Build
### Install dependencies
```bash
# install dependencies for autoware
sudo apt update
sudo apt install -y python-catkin-pkg python-rosdep ros-$ROS_DISTRO-catkin gksu
sudo apt install -y python3-pip python3-colcon-common-extensions python3-setuptools python3-vcstool
pip3 install -U setuptools

sudo apt install -y ros-kinetic-sound_play ros-kinetic-joy
```

### ROS workspace
```bash
cd ~/TC2019/mad_mobile_ws
catkin_make -DCMAKE_BUILD_TYPE=Release
```

### Autoware
```bash
cd ~/TC2019/autoware/ros
rosdep update
rosdep install -y --from-paths src --ignore-src --rosdistro kinetic
catkin_make -DCMAKE_BUILD_TYPE=Release
```

## setup
1. setup velodyne
    1. install package
    ```bash
    sudo apt install ros-kinetic-velodyne
    ```
    1. setup ip address
    <image src="">
    1. check
    ```bash
    roslaunch velodyne_pointcloud 32e_points.launch
    rviz
    ```

1. Get [parameter file]() for MAD mobile and move it to ~/TC2019/Params/

    if you cannot access above link, do this.
    ```bash
    wget
    ```

1. Move [sound file]() for joystick control

    !YOU SHOULD PUT SOUND FILES UNDER ROOT DIR!
    ```bash
    sudo mv ~/path/to/soundfile/*.wav /usr/share/sounds/robot_sounds
    ```
    If you cannot access above link, do this.
    1. get .wav file from anyware to `/usr/share/sounds/robot_sounds`
    1. Edit file path of `~/TC2019/mad_mobile_ws/src/teleop/src/yp_teleop.cpp` *L194~255*

    befor
    ```c
    sc.playWave("/usr/share/sounds/robot_sounds/new_world.wav")
    ```
    after
    ```c
    sc.playWave("/usr/share/sounds/robot_sounds/[sound name]")
    ```

1. Set strage for recording rosbag with joystick (optional)
    1. Attach SSD
    1. Edit `~/TC2019/mad_mobile_ws/src/teleop/src/bag_recorde.sh` *L112~*

    before
    ```bash
    dir=/media/kuriatsu/Samsung_T5/TC2019_bag/$today
    ```
    after
    ```bash
    dir=/media/[username]/[SSD name]/TC2019_bag/$today
    ```

1. Set white line position

    Edit `~/TC2019/mad_mobile_ws/src/tc_helper/whiteline_list.csv`  
    I recommend you to use `point map loader` in Autoware and `initial_pose` in rviz with subscribing topic named `/initial_pose`.  
    Please use any application to read position on the point clond map
    * pose x, y, z : position on the map frame.
    * orientation x, y, z, w : quaternion on the map frame. Set value so that the robot and whiteline face each other.

<a id="set_pc"></a>
# 2. Set PC in the Robot and Run
---
1. Attach Ethernet Cable of LiDAR

1. Attach USB of robot controller

1. Attach USB hub

1. Turn on

<a id="manual"></a>
# 4. Manual control
---
```bash
cd ~/TC2019/mad_mobile_ws
./mad_mobile.sh
```

### Control Robot
<image src="picture/joy.png" width=70%>

* The amount of Accel/Brake press are multiplied by the speed
* Make sure that the control mode is Xinput mode, not Direct input mode. The toggle is behind the controller

### Parameter tuning

<a id="autonomous"></a>
# 5. Autonomous control
---
### 1. Run Autoware
```bash
cd path/to/Autoware
./run
```

### 2. Setup  Autoware
1. setup
<image src="picture/setup.png" width=50%>

    1. `Localizer` : Select localization sensor

    2. `TF` : LiDAR position on the Robot

    3. `Vehicle Model` : Default car model is set if you chose nothing.

1. Map
<image src="picture/map.png" width=50%>  

    1. `Point Cloud` : Path to point_cloud .pcd

    2. `Vector Map` : If you use vector_map to set white line and traffic light on the map, input path to vector_map. If not, ignore this console.

    3. `TF` : Path to tf file. (`/path/to/autoware/ros/.config/tf/tf.launch`)

1. Sensing
<image src="picture/sensing.png" width=50%>  

    1. `Velodyne VLP-16` : Input calibration setting file like `/path/to/Autoware/ros/src/sensing/drivers/lidar/packages/velodyne/velodyne_pointcloud/params/VLP16db.yaml`

    <image src="picture/lidar_vlp16.png" width=50%>  

    1. `voxel grid filter` : Creates a 3D voxel grid (think about a voxel grid as a set of tiny 3D boxes in space) over the input point cloud data. Then, in each voxel, all the points present will be approximated (i.e., downsampled) with their centroid.  

    <image src="picture/vox_grid_filter.png" width=50%>  

        + `leaf size [m]` : Voxel’s length of each side. The bigger this value is, the faster computer is. 0.2 is best value for outside. When you use inside, 0.1 is best.

        + `Measurement Range [m]` : Restrict the range of point cloud data. The smaller this value is, The faster computer is.
            Appropriate value is 50m

    1. `ring_ground_filter` : Remove ground points not to be detected as objects. This filter is best choice compered to other filters. Out put data is broadcast to `/points_no_ground`.

    <image src="picture/ring_ground_filter.png" width=50%>  

1. Computing
<image src="picture/computing.png" width=50%>  

    1. `ndt_matching`
    <image src="picture/ndt.png" width=70%>  

        + `Error Thres`  

        + `Resolution` : It may good to have the same value with *leaf size*

        + `Step Size` : 0.08 is the best value for this Robot’s speed!! This value is my secret spice to make ndt_maching stable ^o^.

        + `Transformation Epsilon` :   

        + `Maximum iteration` : We need not tune this value. Iteration times is actually up to 12~20.

    1. `lidar_euclidean_cluster_detect`  

        <image src="picture/lider_euclidean_cluster.png" width=50%>

        + `input_point_node` : If you use ground_filter, change input node from `/points_raw` to `/points_no_ground`

        + `keep_only_lanes_points` : Restrict detection range to alongside the road. This function reduce the nunber of detected obstacles and makes dp_planner work well.

        + `use_gpu` : *lidar_euclidean_cluster_detect* is heavy burden for computer. By distributing the calculation to GPU make computer work faster.

### 3. move robot to start point
### 4. Run motion planning

1. run `way_planner`

    ```bash
    roslaunch way_planner way_planner.launch
    ```
    Select vector map.  
    If you use one which created in Hatem’s original map tool (which file extension is `.kml` ), check `KML` in **Map Source**.    
    If you use one which created in Autoware map tools, (which file extension is `.csv` ) ,check `Autoware` in **Map Source**.

1. set start point and goalpoint with Rviz (*initial pose*)

1. run `dp_planner`
    ```bash
    roslaunch dp_planner dp_planner_outside2.launch
    ```

    + `Follow Distance [m]`  
    The distance to obstacles in front of the robot. The Robot follow obstacles keeping this distance.

    + `Avoiding Distance [m]` : If the distance to obstacles is this value, the robot will avoid the obstacles.

    + `Avoidance Limit [m]` : If the distance to obstacle is under this value, the robot will stop.

    + `Lateral Safety [m]` : Keep lateral distance from tf origin to obstacles.

    <image src="picture/lateral_safezone.png" width=50%>

    + `Longitudinal Safety [m]` : Keep longitudinal distance from tf origin to obstacles.

### 5. Connect planner to controller

1. `pure_pursuit`
    <image src="picture/pure_pursuit.png" width=50%>

    + `Waypoint` : Run according to the speed described in the Waypoint.

    + `Dialog` : Run according to the speed set in the slider.

1. `twist_filter`
    <image src="picture/twist_filter.png" width=50%>

1. `vel_pose_connect`  
    <image src="picture/vel_pose_connect.png" width=50%>

## 7. Edit code for robot

1. **Run time manager**  
    Lower the minimum of the slider in *runtime_manager* (*dp_planner* [app])  to match the scale for the robot.  
    Change min and max value in
    `/path/to/Autoware/ros/src/util/packages/runtime_manager/scripts/computing.yaml`
    *ln 2480~*

2. **Obstacle Detection**  
    Change condition value in  
    `/path/to/Autoware/ros/src/computing/planning/motion/packages/dp_planner/nodes/RosHelpers.cpp` *ln 565~*

3. **Robot Motion**
    `/path/to/Autoware/ros/src/computing/planning/motion/packages/dp_planner/nodes/dp_planner_core.cpp`
